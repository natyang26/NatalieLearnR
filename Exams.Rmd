---
title: "Exams"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

# Exam 1

a. Create a folder in your computer (a good place would be under Crim 250, Exams). 

b. Download the dataset from the Canvas website (fatal-police-shootings-data.csv) onto that folder, and save your Exam 1.Rmd file in the same folder.

c. Download the README.md file. This is the codebook. 

d. Load the data into an R data frame.
```{r}
# setwd("~/Desktop/Fall 2021/CRIM 250/Crim 250 - Exam 1")
shootings <- read.csv("fatal-police-shootings-data.csv")
shootings.untouched <- shootings
View(shootings)
```

## Problem 1 (10 points)

a. Describe the dataset. This is the source: https://github.com/washingtonpost/data-police-shootings . Write two sentences (max.) about this.

The Washington Post compiled this dataset from a variety of sources (ie. local news, social media, etc.), and it contains relevant information looking at fatal police shootings in the United States dating back to January 1, 2015. The data includes demographics about the victims, as well as information on where the shootings occurred and other details that might be interesting to examine in relation to the shooting. 

b. How many observations are there in the data frame?
```{r}
dim(shootings)
```

There are 6,594 rows (number of fatal shootings) and 17 different columns, each containing information respective to the row. 

c. Look at the names of the variables in the data frame. Describe what "body_camera", "flee", and "armed" represent, according to the codebook. Again, only write one sentence (max) per variable.
```{r}
names(shootings)
```

According to the codebook, "body_camera" refers to whether or not the officer involved in the shooting was wearing a body camera that could have recorded parts of the shooting. The "flee" variable contains data on whether the victim was moving away from the officer during the incident. The "armed" column gives us information on whether the victim was armed, which might have influenced the officer's decision to take action. 

d. What are three weapons that you are surprised to find in the "armed" variable? Make a table of the values in "armed" to see the options.
```{r}
surprising_weapons <- table(unique(shootings$armed))
View(surprising_weapons)
```

Three surprising weapons I found were interesting include the binoculars, microphone, and wasp spray. 

## Problem 2 (10 points)

a. Describe the age distribution of the sample. Is this what you would expect to see?
```{r}
hist(shootings$age,
     main = "Histogram of Ages",
     xlab = "Age",
     ylab = "Frequency",
     xlim = c(0,100))
```

This histogram, which shows the distributions of the victim's ages, shows that the victims are mostly in their 30's. This is overall not surprising, as the median age of adults in the US are roughly 38 years old, so it would make sense that this age range has the most number of victims, also by chance. 

b. To understand the center of the age distribution, would you use a mean or a median, and why? Find the one you picked.
```{r}
shootings$age[which(is.na(shootings$age))] <- 0
length(shootings$age[shootings$age == 0])
mean(shootings$age)
median(shootings$age)
```

This graph is right skewed which means that the mean is greater than the median which is greater than the mode. Because of this, I would probably look at the median, as this value will be the middle value and most accurate number. We can remove the missing values marked as "NA" in the dataset which will allow us to perform calculations on the data that is reported; there are only 308 missing values, and in a dataset with 6,594 observations, this should not disrupt the data too much. The median of the ages reported in the shootings comes out to be 34 years old, which makes sense when comparing this value to the histogram showing the distributions of the ages above. 

c. Describe the gender distribution of the sample. Do you find this surprising?
```{r}
summary(shootings$gender)
```

There are disproportionately more males (6298 cases reported) reported to be fatal victims of police shootings than there are females (293 cases reported). This is not surprising to me, especially because I feel like I more often have heard of males getting shot by police. This has been reflected by the news, especially with all the Black men getting fatally shot by police officers. 

## Problem 3 (10 points)

a. How many police officers had a body camera, according to news reports? What proportion is this of all the incidents in the data? Are you surprised that it is so high or low?

```{r}
length(which(shootings$body_camera == "True"))
length(which(shootings$body_camera == "False"))
910+5684
(910/6594)*100
```

There were 910 police officers who reported wearing body cameras, compared to 5,684 officers who reported that they were not wearing cameras. This only equates to 13.8% roughly, which is a low proportion. This is also not surprised that this is so low, and some hypotheses challenge that body cameras are effective in decreasing police brutality; although, the studies looking at this are relatively inconclusive. The fact that there were some instances in this data, where the officer was wearing a body camera, and the victim was still fatally shot, shows that body cameras are not fully effective and killings will happen even when officers are wearing them. 

b. In  how many of the incidents was the victim fleeing? What proportion is this of the total number of incidents in the data? Is this what you would expect?
```{r}
summary(shootings$flee)
1058+845
1903/6594
```

A total of 1,903 victims were reported to be fleeing, whether this is by car or by foot. This is roughly 28.9% of the victims in the dataset who were reported to be fleeing. This seems about accurate, or even slightly low, although my knowledge on specifics during police interactions is pretty limited. 

## Problem 4 (10 points) -  Answer only one of these (a or b).

a. Describe the relationship between the variables "body camera" and "flee" using a stacked barplot. What can you conclude from this relationship? 

*Hint 1: The categories along the x-axis are the options for "flee", each bar contains information about whether the police officer had a body camera (vertically), and the height along the y-axis shows the frequency of that category).*

*Hint 2: Also, if you are unsure about the syntax for barplot, run ?barplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.*


```{r}
tab.camflee <- table(shootings$body_camera, shootings$flee)
barplot(tab.camflee,
        main = "Barchart - Relationship Between Cameras and Fleeing",
        xlab = "Fleeing",
        ylab = "Frequency",
        legend.text = rownames(tab.camflee),
        beside = FALSE,
        ylim = c(0,4000))
```

This barchart shows the relationship between wearing a body camera and when the victims were fleeing. In terms of frequency, there were more officers wearing a body camera in the instances where the victim was not fleeing, but in terms of proportions, there were probably equal or even lesser number of officers wearing cameras when the victim was fleeing. Other than that, it is clear that in this dataset, officers were way more likely to not be wearing cameras across the board, no matter if the victim was fleeing or not. 

b. Describe the relationship between age and race by using a boxplot. What can you conclude from this relationship? 

*Hint 1: The categories along the x-axis are the race categories and the height along the y-axis is age.* 

*Hint 2: Also, if you are unsure about the syntax for boxplot, run ?boxplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.*


```{r}

```

__Your answer here.__

## Extra credit (10 points)

a. What does this code tell us? 

```{r, eval=FALSE}
mydates <- as.Date(shootings$date)
head(mydates)
(mydates[length(mydates)] - mydates[1])
```

The first line of code is changing the values in the date column and converting them to the character representation of how dates are in a calendar. This will allow us to manipulate the data in terms of date specific analysis, rather than having to treat it as the value that it is in the input stage. head(mydates) allows us to look at the first few values of the newly changed data. The last line of code allows us to look at the difference from where we are now, to the origin of the data, or the first date that was input. 

b. On Friday, a new report was published that was described as follows by The Guardian: "More than half of US police killings are mislabelled or not reported, study finds." Without reading this article now (due to limited time), why do you think police killings might be mislabelled or underreported?

I think there are many reasons why police killings would be mislabelled or underreported. There are many reasons why someone in the reporting process would want to change or withhold information in order to protect the officers involved in the shooting and the police force as a whole. I think it is important to take these factors into consideration when looking at any data that goes through the policing system, as there is a lot of personal incentive to not provide the whole truth, especially when police are under the microscope right now and some may feel the need to alter or not provide certain details in order to protect themselves. 

c. Regarding missing values in problem 4, do you see any? If so, do you think that's all that's missing from the data?
```{r}
summary(shootings$flee)
summary(shootings$body_camera)
```

There are missing values in the data we used for problem 4, specifically for the variable looking at victim fleeing. That is most likely not all the data that is missing from this dataset, as it is hard to compile complete information when looking at data like this. Overall, this dataset is pretty complete, and while it is always best practice to try to get as much information as possible, with such a large number of observations, missing data is not always the biggest deal. A lot of the times, you have to work with what you are provided with. 

# Exam 2

a. Create a folder in your computer (a good place would be under Crim 250, Exams). 

b. Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.

c. Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: **"Does having more funding in a police department lead to fewer incidents of police brutality?"**

d. Codebook:
- funds: How much funding the police department received in that year in millions of dollars.
- po.brut: How many incidents of police brutality were reported by the department that year.
- po.dept.code: Police department code

## Problem 1: EDA (10 points) 

Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.

```{r}
setwd("~/Desktop/Fall 2021/CRIM 250/Crim 250 - Exam 2")
dat <- read.csv(file = 'sim.data.csv')
library(datasets)
library(ggplot2)
```

```{r}
dim(dat)
names(dat)
```
There are 200 row observations and 3 columns with data respective to the unique identifying police department code. 

```{r}
hist(dat$funds)
summary(dat$funds)
```
The histogram shows the distribution of funds across the different police department, with the most common amount of funding falling within the $50-60 million range. The least given to a department was $21.4 million, and then most was $99.7 million. 

```{r}
hist(dat$po.brut)
summary(dat$po.brut)
```
The histogram shows a distribution regarding the number of police brutality cases reported by the department that year. Most frequently, there were between 15-20 cases reported, although the 20-25 range was close behind that range. The least number of police brutality cases reported in a given year was 0, while the highest number of cases was 29.

## Problem 2: Linear regression (30 points)

a. Perform a simple linear regression to answer the question of interest. To do this, name your linear model "reg.output" and write the summary of the regression by using "summary(reg.output)". 

```{r}
# Remember to remove eval=FALSE!!
reg.output <- lm(po.brut ~ funds, data = dat)
summary(reg.output)
plot(reg.output)
```
Based on this simple linear regression, we can see that there is a negative correlation between funds and police brutality cases reported. To answer the question above, for every 1 unit increase in funding, the likelihood of police brutality decreases by 0.367 units. We cannot conclude that more funding will decrease the number of actual incidents, we can only draw a conclusionship between funding and the number of incidents reported. While it is not a causal relationship, this ultimately means that as funding increases, the likelihood that police brutality cases will be reported decreases. 

b. Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain.

Based on the summary of the regression output above, the estimated coefficient shows 2 values. The first is the intercept which is 40.54, and the other value shows more about the relationship between the two variables being compared. The value is -0.367 and I explained how this value gives us important information in 2a. The standard error value is 0.9464, and the p value is < 2.2e-16. Because this p value is < 0.05, we can reject the null hypothesis with 95% certainty, and we can say that this relationship is statisticallly significant. 

c. Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:
```{r, fig.width=4, fig.height=4}
ggplot(dat, aes(x = funds, y = po.brut)) + 
    geom_point() +
    geom_smooth(method = lm, se=FALSE)

cor(dat$funds,
    dat$po.brut,
    method = "pearson",
    use = "complete.obs")
```

```{r}
reg.output.nc <- lm(formula = dist ~ speed, data = cars)

plot(dat$funds, dat$po.brut,  main="Relationship between Funding and Police Brutality Reports",
    xlab="Funds", ylab="Police Brutality Cases Reported")
abline(reg.output, col="blue")
```
Does the line look like a good fit? Why or why not?

This line looks like a decent fit for the data. Given that the R^2 is 0.971, it is almost close to 100%. This value helps us determine whether the model is a good fit for the data. Additionally, the relationship is relatively linear, so that also is a good indication that the line is a good fit. 

d. Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?

```{r} 
# Linearity
x <- dat$funds
y <- dat$po.brut

## residuals vs x
plot(x, y, main = "Relationship between Funds and Police Brutality Reported",
     xlab = "Funds", ylab = "Police Brutality Reported",
     pch = 19, frame = FALSE)
abline(reg.output, col = "blue")

## residuals vs fitted
plot(reg.output, which=1)

# Normal Population
## qq plot
plot(reg.output, which=2)
## residual vs leverage
plot(reg.output, which=5)

# Homoscedasticity
## scale location plot
plot(reg.output, which=3)
```
Linearity assumption: While the scatterplot abline shows a consistent linear relationship between the variables, the red line in the residuals vs fitted graph is not very flat which indicates there is a discernible non-linear trend to the residuals. In this case, we cannot claim that the linearity assumption is satisfied. 
Equal variation assumption (homoscedasticity): Homoscedasticity looks at each point's distance away from the line, and most of the dots are constantly the same distance for their respective points.
Normal population assumption: There is a little bit of a left skew on this normal qq plot, but overall the distribution looks fine. 
Independence assumption: It is impossible to truly test this assumption visually, and there's no time series data available. Because there is a pattern in the scatterplot, this might not pass the independence assumption. 

## Problem 3: Data ethics (10 points)

Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?

This dataset looks at the funding of 200 different police department's funding, with their respective annual number regarding police brutality cases reported. I am concerned about the actual data in the dataset, given that the number of police brutality cases might not actually be accurately reported. There are many selfish/protective incentives, on the police department's side, to not report the number of police brutality cases. It would be helpful to have time series data in order to look at different trends over the years, as it is hard to draw longer-term conclusions and see patterns with only one year of data. If anyone were to use this model/analyses for future reference, I would caution them to ensure that biased data does not continue to reinforce any biases. It would be helpful to have more factors/more data in this dataset to add to the regression because I am positive that the amount of funding is not the only influence on the likelihood of whether police brutality cases are reported.
